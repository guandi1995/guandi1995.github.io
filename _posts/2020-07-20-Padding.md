---
title: "Padding"
date: 2020-07-20
tags: [machine learning, data science, convolutional neural network]

excerpt: "Machine Learning, Data Science, Optimization"
mathjax: "true"
---

## Padding

To build a deep neural network, we need to be familiar with the basic convolutional operation such as padding, strides, convolution, pooling and etc.

In convolutional neural network, a convolutional layer is applied to one or more filters to an input in order to generate output. The input is typically 3-dimensional images (height, width, channels). the filters are also 3-dimensional shape with the same number of channels with different heights and widths (commonly 3 by 3 or 5 by 5). As such, the filters are repeatedly applied to each part of  the input image, which results in a feature map.

For instance, there is a $$6 \times 6\times 1$$ image and we want to convolve it with a $$3\times 3\times 1$$ filter. The resulting output will be $$4 \times 4\times 1$$, which illustrated below.

In general, an input with $$n \times n\times c$$ convolved with a $$f \times f\times c$$ filter will generate a $$(n-f+1) \times (n-f+1) \times c$$ output. In order word, the shape of output shrinks every time when convolutional operations are completed. It will result in a really small output shape without any padding, which is the problem that you want to avoid. On the other hand, the corner pixels of the image only convolve much less times than the others. It throws away a lot of information near the edge of the input.

To solve both of the problems aforementioned, we typically apply padding to avoid.
